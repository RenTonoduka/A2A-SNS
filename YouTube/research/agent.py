"""
YouTube Research Agent
TubeAIã®ã‚³ã‚¢æ©Ÿèƒ½ã‚’æŠ½å‡ºã—ãŸãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

æ©Ÿèƒ½:
1. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¸‚å ´åˆ†æ
2. ç«¶åˆãƒãƒ£ãƒ³ãƒãƒ«ç™ºè¦‹
3. ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
4. æ©Ÿä¼šã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
"""

import os
import sys
import json
from typing import Optional, List, Dict, Any
from dataclasses import dataclass, asdict
from datetime import datetime

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
SNS_DIR = os.path.dirname(os.path.dirname(SCRIPT_DIR))
sys.path.insert(0, SNS_DIR)

from _shared.claude_runner import ClaudeRunner


@dataclass
class ChannelData:
    """ãƒãƒ£ãƒ³ãƒãƒ«æƒ…å ±"""
    channel_id: str
    title: str
    subscriber_count: int
    view_count: int
    video_count: int
    engagement_rate: float = 0.0
    opportunity_score: float = 0.0


@dataclass
class KeywordData:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æƒ…å ±"""
    keyword: str
    search_volume: int = 0
    competition: str = "medium"  # low, medium, high
    opportunity_score: float = 0.0
    related_keywords: List[str] = None

    def __post_init__(self):
        if self.related_keywords is None:
            self.related_keywords = []


@dataclass
class ResearchResult:
    """ãƒªã‚µãƒ¼ãƒçµæœ"""
    theme: str
    timestamp: str
    keywords: List[KeywordData]
    channels: List[ChannelData]
    trends: List[str]
    content_ideas: List[str]
    strategy_suggestions: List[str]


class YouTubeResearchAgent:
    """
    YouTubeãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

    TubeAIã®ã‚³ã‚¢æ©Ÿèƒ½ã‚’æŠ½å‡º:
    - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆãƒ»åˆ†æ
    - ç«¶åˆãƒãƒ£ãƒ³ãƒãƒ«ç™ºè¦‹
    - æ©Ÿä¼šã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    - æˆ¦ç•¥ææ¡ˆ
    """

    def __init__(self, workspace: str = "."):
        self.workspace = workspace
        self.claude = ClaudeRunner(workspace=workspace, timeout=180)

        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.system_prompt = """ã‚ãªãŸã¯YouTubeãƒãƒ¼ã‚±ãƒƒãƒˆãƒªã‚µãƒ¼ãƒã®å°‚é–€å®¶ã§ã™ã€‚

## å½¹å‰²
- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¸‚å ´åˆ†æ
- ç«¶åˆãƒãƒ£ãƒ³ãƒãƒ«ç™ºè¦‹ã¨è©•ä¾¡
- ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã¨æ©Ÿä¼šç‰¹å®š
- ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æˆ¦ç•¥ææ¡ˆ

## åˆ†æã®è¦³ç‚¹
1. æ¤œç´¢ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆéœ€è¦ã®å¤§ãã•ï¼‰
2. ç«¶äº‰åº¦ï¼ˆå‚å…¥éšœå£ï¼‰
3. æˆé•·ç‡ï¼ˆãƒˆãƒ¬ãƒ³ãƒ‰æ€§ï¼‰
4. åç›Šæ€§ï¼ˆCPMã€åºƒå‘Šå˜ä¾¡ï¼‰
5. è¦–è´è€…ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ

## å‡ºåŠ›å½¢å¼
å¿…ãšJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""

    def research_theme(self, theme: str, language: str = "ja") -> ResearchResult:
        """
        ãƒ†ãƒ¼ãƒã«åŸºã¥ãç·åˆãƒªã‚µãƒ¼ãƒ

        Args:
            theme: ãƒªã‚µãƒ¼ãƒãƒ†ãƒ¼ãƒï¼ˆä¾‹: "AIå‰¯æ¥­", "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å­¦ç¿’"ï¼‰
            language: è¨€èªã‚³ãƒ¼ãƒ‰

        Returns:
            ResearchResult: ãƒªã‚µãƒ¼ãƒçµæœ
        """
        prompt = f"""{self.system_prompt}

## ã‚¿ã‚¹ã‚¯
ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒã«ã¤ã„ã¦YouTubeå¸‚å ´ãƒªã‚µãƒ¼ãƒã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ: {theme}
è¨€èª: {language}

## å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰
{{
    "keywords": [
        {{
            "keyword": "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
            "search_volume_estimate": "high/medium/low",
            "competition": "high/medium/low",
            "opportunity_score": 0-100,
            "related_keywords": ["é–¢é€£1", "é–¢é€£2"]
        }}
    ],
    "trending_topics": ["ãƒˆãƒ¬ãƒ³ãƒ‰1", "ãƒˆãƒ¬ãƒ³ãƒ‰2"],
    "content_ideas": [
        "å‹•ç”»ã‚¢ã‚¤ãƒ‡ã‚¢1",
        "å‹•ç”»ã‚¢ã‚¤ãƒ‡ã‚¢2"
    ],
    "competitor_channels": [
        {{
            "channel_name": "ãƒãƒ£ãƒ³ãƒãƒ«å",
            "subscriber_estimate": "10ä¸‡ä»¥ä¸Š/1-10ä¸‡/1ä¸‡æœªæº€",
            "content_style": "æ•™è‚²ç³»/ã‚¨ãƒ³ã‚¿ãƒ¡ç³»/etc",
            "strength": "å¼·ã¿",
            "weakness": "å¼±ã¿"
        }}
    ],
    "strategy_suggestions": [
        "æˆ¦ç•¥ææ¡ˆ1",
        "æˆ¦ç•¥ææ¡ˆ2"
    ],
    "market_summary": "å¸‚å ´ã®ç·åˆè©•ä¾¡ï¼ˆ2-3æ–‡ï¼‰"
}}

JSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""

        result = self.claude.run(prompt)

        if not result["success"]:
            raise Exception(f"Research failed: {result['error']}")

        return self._parse_research_result(theme, result["output"])

    def analyze_keyword(self, keyword: str) -> KeywordData:
        """
        å˜ä¸€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®è©³ç´°åˆ†æ
        """
        prompt = f"""{self.system_prompt}

## ã‚¿ã‚¹ã‚¯
ä»¥ä¸‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ã¤ã„ã¦YouTubeå¸‚å ´åˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keyword}

## å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰
{{
    "keyword": "{keyword}",
    "search_volume_estimate": "high/medium/low",
    "competition": "high/medium/low",
    "opportunity_score": 0-100,
    "related_keywords": ["é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", ...],
    "recommended_title_patterns": ["ãƒ‘ã‚¿ãƒ¼ãƒ³1", "ãƒ‘ã‚¿ãƒ¼ãƒ³2"],
    "content_angle_suggestions": ["åˆ‡ã‚Šå£1", "åˆ‡ã‚Šå£2"],
    "target_audience": "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¦–è´è€…ã®èª¬æ˜",
    "monetization_potential": "high/medium/low"
}}

JSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""

        result = self.claude.run(prompt)

        if not result["success"]:
            raise Exception(f"Keyword analysis failed: {result['error']}")

        return self._parse_keyword_result(result["output"])

    def discover_competitors(self, niche: str, limit: int = 10) -> List[Dict[str, Any]]:
        """
        ãƒ‹ãƒƒãƒåˆ†é‡ã®ç«¶åˆãƒãƒ£ãƒ³ãƒãƒ«ç™ºè¦‹
        """
        prompt = f"""{self.system_prompt}

## ã‚¿ã‚¹ã‚¯
ä»¥ä¸‹ã®ãƒ‹ãƒƒãƒåˆ†é‡ã§æ³¨ç›®ã™ã¹ãYouTubeãƒãƒ£ãƒ³ãƒãƒ«ã‚’{limit}å€‹ç™ºè¦‹ã—ã¦ãã ã•ã„ã€‚

ãƒ‹ãƒƒãƒ: {niche}

## å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰
{{
    "competitors": [
        {{
            "channel_name": "ãƒãƒ£ãƒ³ãƒãƒ«å",
            "niche_fit": "high/medium/low",
            "estimated_subscribers": "æ¦‚ç®—ç™»éŒ²è€…æ•°",
            "content_frequency": "æŠ•ç¨¿é »åº¦",
            "content_style": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¹ã‚¿ã‚¤ãƒ«",
            "unique_value": "ç‹¬è‡ªã®ä¾¡å€¤",
            "strengths": ["å¼·ã¿1", "å¼·ã¿2"],
            "weaknesses": ["å¼±ã¿1"],
            "opportunity_to_beat": "å‹ã¦ã‚‹ãƒã‚¤ãƒ³ãƒˆ"
        }}
    ],
    "market_gaps": ["ã‚®ãƒ£ãƒƒãƒ—1", "ã‚®ãƒ£ãƒƒãƒ—2"],
    "differentiation_opportunities": ["å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆ1", "å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆ2"]
}}

JSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""

        result = self.claude.run(prompt)

        if not result["success"]:
            raise Exception(f"Competitor discovery failed: {result['error']}")

        try:
            data = json.loads(self._extract_json(result["output"]))
            return data.get("competitors", [])
        except json.JSONDecodeError:
            return []

    def generate_content_ideas(self, theme: str, count: int = 10) -> List[Dict[str, Any]]:
        """
        ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆ
        """
        prompt = f"""{self.system_prompt}

## ã‚¿ã‚¹ã‚¯
ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒã§è¦–è´è€…ã‚’æƒ¹ãã¤ã‘ã‚‹YouTubeå‹•ç”»ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’{count}å€‹ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ: {theme}

## å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰
{{
    "ideas": [
        {{
            "title": "å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«æ¡ˆ",
            "hook": "å†’é ­ã®ãƒ•ãƒƒã‚¯ï¼ˆæœ€åˆã®5ç§’ï¼‰",
            "target_audience": "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¦–è´è€…",
            "estimated_length": "æƒ³å®šå°ºï¼ˆåˆ†ï¼‰",
            "content_structure": ["ã‚»ã‚¯ã‚·ãƒ§ãƒ³1", "ã‚»ã‚¯ã‚·ãƒ§ãƒ³2", ...],
            "cta": "è¡Œå‹•å–šèµ·",
            "thumbnail_concept": "ã‚µãƒ ãƒã‚¤ãƒ«ã‚³ãƒ³ã‚»ãƒ—ãƒˆ",
            "viral_potential": "high/medium/low",
            "production_difficulty": "high/medium/low"
        }}
    ]
}}

JSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""

        result = self.claude.run(prompt)

        if not result["success"]:
            raise Exception(f"Content idea generation failed: {result['error']}")

        try:
            data = json.loads(self._extract_json(result["output"]))
            return data.get("ideas", [])
        except json.JSONDecodeError:
            return []

    def analyze_trends(self, category: str = "technology") -> Dict[str, Any]:
        """
        ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        """
        prompt = f"""{self.system_prompt}

## ã‚¿ã‚¹ã‚¯
YouTubeã®{category}ã‚«ãƒ†ã‚´ãƒªã«ãŠã‘ã‚‹æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

## å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰
{{
    "category": "{category}",
    "analysis_date": "{datetime.now().strftime('%Y-%m-%d')}",
    "rising_topics": [
        {{
            "topic": "ãƒˆãƒ”ãƒƒã‚¯å",
            "growth_rate": "æ€¥ä¸Šæ˜‡/ä¸Šæ˜‡ä¸­/å®‰å®š",
            "peak_timing": "ãƒ”ãƒ¼ã‚¯äºˆæ¸¬",
            "content_opportunity": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ©Ÿä¼šã®èª¬æ˜"
        }}
    ],
    "declining_topics": ["ä¸‹é™ãƒˆãƒ”ãƒƒã‚¯1", "ä¸‹é™ãƒˆãƒ”ãƒƒã‚¯2"],
    "evergreen_topics": ["å¸¸ç·‘ãƒˆãƒ”ãƒƒã‚¯1", "å¸¸ç·‘ãƒˆãƒ”ãƒƒã‚¯2"],
    "format_trends": {{
        "popular_formats": ["ã‚·ãƒ§ãƒ¼ãƒˆ", "è§£èª¬", "Vlog", ...],
        "emerging_formats": ["æ–°å½¢å¼1", "æ–°å½¢å¼2"]
    }},
    "audience_behavior": {{
        "preferred_length": "å¥½ã¾ã‚Œã‚‹å‹•ç”»å°º",
        "engagement_patterns": "ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³",
        "peak_viewing_times": "è¦–è´ãƒ”ãƒ¼ã‚¯æ™‚é–“"
    }},
    "recommendations": ["æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³1", "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³2"]
}}

JSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""

        result = self.claude.run(prompt)

        if not result["success"]:
            raise Exception(f"Trend analysis failed: {result['error']}")

        try:
            return json.loads(self._extract_json(result["output"]))
        except json.JSONDecodeError:
            return {"error": "Failed to parse trends"}

    def _extract_json(self, text: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰JSONéƒ¨åˆ†ã‚’æŠ½å‡º"""
        # ```json ... ``` ã‚’é™¤å»
        if "```json" in text:
            start = text.find("```json") + 7
            end = text.find("```", start)
            if end > start:
                return text[start:end].strip()

        # ```ã‚’é™¤å»
        if "```" in text:
            start = text.find("```") + 3
            end = text.find("```", start)
            if end > start:
                return text[start:end].strip()

        # { ã‹ã‚‰å§‹ã¾ã‚‹éƒ¨åˆ†ã‚’æ¢ã™
        start = text.find("{")
        if start >= 0:
            # å¯¾å¿œã™ã‚‹ } ã‚’æ¢ã™
            depth = 0
            for i, c in enumerate(text[start:]):
                if c == "{":
                    depth += 1
                elif c == "}":
                    depth -= 1
                    if depth == 0:
                        return text[start:start + i + 1]

        return text

    def _parse_research_result(self, theme: str, output: str) -> ResearchResult:
        """ãƒªã‚µãƒ¼ãƒçµæœã‚’ãƒ‘ãƒ¼ã‚¹"""
        try:
            data = json.loads(self._extract_json(output))

            keywords = []
            for kw in data.get("keywords", []):
                keywords.append(KeywordData(
                    keyword=kw.get("keyword", ""),
                    search_volume=self._estimate_volume(kw.get("search_volume_estimate", "medium")),
                    competition=kw.get("competition", "medium"),
                    opportunity_score=kw.get("opportunity_score", 50),
                    related_keywords=kw.get("related_keywords", [])
                ))

            channels = []
            for ch in data.get("competitor_channels", []):
                channels.append(ChannelData(
                    channel_id="",
                    title=ch.get("channel_name", ""),
                    subscriber_count=self._estimate_subscribers(ch.get("subscriber_estimate", "")),
                    view_count=0,
                    video_count=0
                ))

            return ResearchResult(
                theme=theme,
                timestamp=datetime.now().isoformat(),
                keywords=keywords,
                channels=channels,
                trends=data.get("trending_topics", []),
                content_ideas=data.get("content_ideas", []),
                strategy_suggestions=data.get("strategy_suggestions", [])
            )

        except json.JSONDecodeError:
            return ResearchResult(
                theme=theme,
                timestamp=datetime.now().isoformat(),
                keywords=[],
                channels=[],
                trends=[],
                content_ideas=[],
                strategy_suggestions=[]
            )

    def _parse_keyword_result(self, output: str) -> KeywordData:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµæœã‚’ãƒ‘ãƒ¼ã‚¹"""
        try:
            data = json.loads(self._extract_json(output))
            return KeywordData(
                keyword=data.get("keyword", ""),
                search_volume=self._estimate_volume(data.get("search_volume_estimate", "medium")),
                competition=data.get("competition", "medium"),
                opportunity_score=data.get("opportunity_score", 50),
                related_keywords=data.get("related_keywords", [])
            )
        except json.JSONDecodeError:
            return KeywordData(keyword="", search_volume=0)

    def _estimate_volume(self, estimate: str) -> int:
        """æ¤œç´¢ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®æ¦‚ç®—å€¤"""
        mapping = {
            "high": 100000,
            "medium": 10000,
            "low": 1000
        }
        return mapping.get(estimate.lower(), 10000)

    def _estimate_subscribers(self, estimate: str) -> int:
        """ç™»éŒ²è€…æ•°ã®æ¦‚ç®—å€¤"""
        if "10ä¸‡" in estimate or "100k" in estimate.lower():
            return 100000
        elif "1ä¸‡" in estimate or "10k" in estimate.lower():
            return 10000
        elif "1-10ä¸‡" in estimate:
            return 50000
        return 5000

    def save_result(self, result: ResearchResult, output_dir: str = "./research_results"):
        """ãƒªã‚µãƒ¼ãƒçµæœã‚’ä¿å­˜"""
        os.makedirs(output_dir, exist_ok=True)

        filename = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{result.theme.replace(' ', '_')}.json"
        filepath = os.path.join(output_dir, filename)

        # dataclassã‚’dictã«å¤‰æ›
        data = {
            "theme": result.theme,
            "timestamp": result.timestamp,
            "keywords": [asdict(kw) for kw in result.keywords],
            "channels": [asdict(ch) for ch in result.channels],
            "trends": result.trends,
            "content_ideas": result.content_ideas,
            "strategy_suggestions": result.strategy_suggestions
        }

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        return filepath


# CLIå®Ÿè¡Œç”¨
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="YouTube Research Agent")
    parser.add_argument("theme", help="Research theme")
    parser.add_argument("--output", "-o", default="./research_results", help="Output directory")
    args = parser.parse_args()

    print(f"ğŸ” Researching: {args.theme}")
    print("=" * 50)

    agent = YouTubeResearchAgent()

    try:
        result = agent.research_theme(args.theme)

        print(f"\nğŸ“Š Keywords ({len(result.keywords)}):")
        for kw in result.keywords[:5]:
            print(f"  â€¢ {kw.keyword} (Score: {kw.opportunity_score})")

        print(f"\nğŸ“ˆ Trends ({len(result.trends)}):")
        for trend in result.trends[:5]:
            print(f"  â€¢ {trend}")

        print(f"\nğŸ’¡ Content Ideas ({len(result.content_ideas)}):")
        for idea in result.content_ideas[:5]:
            print(f"  â€¢ {idea}")

        print(f"\nğŸ¯ Strategy Suggestions ({len(result.strategy_suggestions)}):")
        for suggestion in result.strategy_suggestions[:3]:
            print(f"  â€¢ {suggestion}")

        # çµæœã‚’ä¿å­˜
        filepath = agent.save_result(result, args.output)
        print(f"\nâœ… Saved to: {filepath}")

    except Exception as e:
        print(f"âŒ Error: {e}")
