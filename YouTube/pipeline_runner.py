"""
YouTube Pipeline Runner - è‡ªå‹•ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
ãƒãƒ£ãƒ³ãƒãƒ«ãƒªã‚¹ãƒˆã‹ã‚‰è‡ªå‹•ã§å°æœ¬ç”Ÿæˆã‚’è¡Œã†
"""

import os
import sys
import json
import asyncio
import urllib.request
import urllib.error
from datetime import datetime
from typing import Optional, Dict, Any, List
from dataclasses import dataclass, asdict
from pathlib import Path

# ãƒ‘ã‚¹è¨­å®š
SCRIPT_DIR = Path(__file__).parent
SNS_DIR = SCRIPT_DIR.parent
sys.path.insert(0, str(SNS_DIR))

from _shared.mcp_tools import LOG_SPREADSHEET_ID, NOTIFY_EMAIL

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
OUTPUT_DIR = SCRIPT_DIR / "output"
SCRIPTS_DIR = OUTPUT_DIR / "scripts"      # ç”Ÿæˆä¸­ã®å°æœ¬
CONCEPTS_DIR = OUTPUT_DIR / "concepts"    # ã‚³ãƒ³ã‚»ãƒ—ãƒˆ
REVIEWS_DIR = OUTPUT_DIR / "reviews"      # ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœ
FINAL_DIR = OUTPUT_DIR / "final"          # å®Œæˆå°æœ¬ï¼ˆ90ç‚¹ä»¥ä¸Šï¼‰

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆURL
AGENTS = {
    # Phase 1: Data Collection
    "channel_monitor": "http://localhost:8110",
    "video_collector": "http://localhost:8111",
    "trend_analyzer": "http://localhost:8112",
    # Phase 2: Script Generation
    "coordinator": "http://localhost:8100",
    "research": "http://localhost:8101",
    "hook": "http://localhost:8102",
    "concept": "http://localhost:8103",
    "reviewer": "http://localhost:8104",
    "improver": "http://localhost:8105",
    "script_writer": "http://localhost:8113",  # æœ¬ç·¨ä½œæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
}


@dataclass
class PipelineResult:
    """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œçµæœ"""
    theme: str
    status: str  # success, failed, in_progress
    final_score: int
    iterations: int
    started_at: str
    completed_at: str
    output_files: Dict[str, str]
    error: Optional[str] = None


class PipelineRunner:
    """
    è‡ªå‹•ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚¯ãƒ©ã‚¹

    æ©Ÿèƒ½:
    - ãƒãƒ£ãƒ³ãƒãƒ«ãƒªã‚¹ãƒˆã‹ã‚‰å„ªç§€å‹•ç”»ã‚’åˆ†æ
    - ãƒ†ãƒ¼ãƒã‚’è‡ªå‹•ç”Ÿæˆ
    - å°æœ¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œ
    - å®Œæˆå°æœ¬ã‚’ä¿å­˜ãƒ»é€šçŸ¥
    """

    def __init__(self, timeout: int = 600):
        self.timeout = timeout

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        for d in [OUTPUT_DIR, SCRIPTS_DIR, CONCEPTS_DIR, REVIEWS_DIR, FINAL_DIR]:
            d.mkdir(parents=True, exist_ok=True)

    async def close(self):
        pass  # urllib doesn't need cleanup

    # ==========================================
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé€šä¿¡
    # ==========================================

    async def call_agent(self, agent: str, message: str) -> Dict[str, Any]:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å‘¼ã³å‡ºã™"""
        url = f"{AGENTS[agent]}/a2a/tasks/send"

        payload = {
            "message": {
                "role": "user",
                "parts": [{"type": "text", "text": message}]
            }
        }

        try:
            data = json.dumps(payload).encode('utf-8')
            req = urllib.request.Request(
                url,
                data=data,
                headers={'Content-Type': 'application/json'},
                method='POST'
            )
            with urllib.request.urlopen(req, timeout=self.timeout) as response:
                return json.loads(response.read().decode('utf-8'))
        except Exception as e:
            return {"error": str(e), "status": {"state": "failed"}}

    async def check_agents(self) -> Dict[str, bool]:
        """å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç¨¼åƒçŠ¶æ³ã‚’ç¢ºèª"""
        status = {}
        for name, base_url in AGENTS.items():
            try:
                req = urllib.request.Request(f"{base_url}/.well-known/agent.json")
                with urllib.request.urlopen(req, timeout=5) as response:
                    status[name] = response.status == 200
            except:
                status[name] = False
        return status

    # ==========================================
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
    # ==========================================

    async def run_pipeline(
        self,
        theme: str,
        max_iterations: int = 3,
        target_score: int = 90
    ) -> PipelineResult:
        """
        å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ

        Args:
            theme: å‹•ç”»ãƒ†ãƒ¼ãƒ
            max_iterations: æœ€å¤§æ”¹å–„å›æ•°
            target_score: ç›®æ¨™ã‚¹ã‚³ã‚¢

        Returns:
            PipelineResult
        """
        started_at = datetime.now()
        timestamp = started_at.strftime("%Y%m%d_%H%M%S")
        safe_theme = theme.replace("/", "_").replace(" ", "_")[:30]

        output_files = {}
        current_score = 0
        iterations = 0

        print(f"\n{'='*60}")
        print(f"ğŸ¬ Pipeline Start: {theme}")
        print(f"{'='*60}")

        try:
            # Phase 1: Research
            print("\n[Phase 1] Research...")
            research_result = await self.call_agent(
                "research",
                f"ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒã§ç«¶åˆåˆ†æã‚’è¡Œã£ã¦ãã ã•ã„:\n\nãƒ†ãƒ¼ãƒ: {theme}\n\n"
                "ãƒ»ä¸Šä½å‹•ç”»10ä»¶ã®åˆ†æ\n"
                "ãƒ»ã‚¿ã‚¤ãƒˆãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º\n"
                "ãƒ»è¦–è´è€…ã®ä¸æº€ãƒ»ã‚®ãƒ£ãƒƒãƒ—"
            )

            research_output = self._extract_output(research_result)
            research_file = SCRIPTS_DIR / f"{timestamp}_{safe_theme}_1_research.md"
            research_file.write_text(research_output, encoding="utf-8")
            output_files["research"] = str(research_file)
            print(f"  âœ… Research complete: {research_file.name}")

            # Phase 2: Hook + Concept (ä¸¦åˆ—)
            print("\n[Phase 2] Hook & Concept...")
            hook_task = self.call_agent(
                "hook",
                f"ãƒ†ãƒ¼ãƒ: {theme}\n\nãƒªã‚µãƒ¼ãƒçµæœ:\n{research_output[:2000]}\n\n"
                "ä¸Šè¨˜ã‚’è¸ã¾ãˆã¦ãƒ•ãƒƒã‚¯æ–‡ã‚’3æ¡ˆç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
            )
            concept_task = self.call_agent(
                "concept",
                f"ãƒ†ãƒ¼ãƒ: {theme}\n\nãƒªã‚µãƒ¼ãƒçµæœ:\n{research_output[:2000]}\n\n"
                "ä¸Šè¨˜ã‚’è¸ã¾ãˆã¦15åˆ†å°æœ¬ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
            )

            hook_result, concept_result = await asyncio.gather(hook_task, concept_task)

            hook_output = self._extract_output(hook_result)
            hook_file = CONCEPTS_DIR / f"{timestamp}_{safe_theme}_2_hook.md"
            hook_file.write_text(hook_output, encoding="utf-8")
            output_files["hook"] = str(hook_file)
            print(f"  âœ… Hook complete: {hook_file.name}")

            concept_output = self._extract_output(concept_result)
            concept_file = CONCEPTS_DIR / f"{timestamp}_{safe_theme}_2_concept.md"
            concept_file.write_text(concept_output, encoding="utf-8")
            output_files["concept"] = str(concept_file)
            print(f"  âœ… Concept complete: {concept_file.name}")

            # å°æœ¬çµ±åˆ
            current_script = f"# {theme}\n\n## ãƒ•ãƒƒã‚¯\n{hook_output}\n\n## å°æœ¬\n{concept_output}"

            # Phase 3-4: Review & Improve ãƒ«ãƒ¼ãƒ—
            while iterations < max_iterations:
                iterations += 1
                print(f"\n[Phase 3] Review #{iterations}...")

                review_result = await self.call_agent(
                    "reviewer",
                    f"ä»¥ä¸‹ã®å°æœ¬ã‚’100ç‚¹æº€ç‚¹ã§è©•ä¾¡ã—ã¦ãã ã•ã„:\n\n{current_script}"
                )

                review_output = self._extract_output(review_result)
                review_file = REVIEWS_DIR / f"{timestamp}_{safe_theme}_3_review_{iterations}.md"
                review_file.write_text(review_output, encoding="utf-8")
                output_files[f"review_{iterations}"] = str(review_file)

                # ã‚¹ã‚³ã‚¢æŠ½å‡º
                current_score = self._extract_score(review_output)
                print(f"  ğŸ“Š Score: {current_score}/100")

                if current_score >= target_score:
                    print(f"  âœ… Target achieved! ({current_score} >= {target_score})")
                    break

                if iterations < max_iterations:
                    print(f"\n[Phase 4] Improve #{iterations}...")
                    improve_result = await self.call_agent(
                        "improver",
                        f"ä»¥ä¸‹ã®å°æœ¬ã‚’æ”¹å–„ã—ã¦ãã ã•ã„:\n\n"
                        f"## ç¾åœ¨ã®å°æœ¬\n{current_script}\n\n"
                        f"## ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœ\n{review_output}"
                    )

                    improve_output = self._extract_output(improve_result)
                    current_script = improve_output

                    improve_file = SCRIPTS_DIR / f"{timestamp}_{safe_theme}_4_improve_{iterations}.md"
                    improve_file.write_text(improve_output, encoding="utf-8")
                    output_files[f"improve_{iterations}"] = str(improve_file)
                    print(f"  âœ… Improvement complete")

            # Phase 5: Script Writerï¼ˆæœ¬ç·¨ä½œæˆ - ç«¶åˆãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆåˆ†æï¼‰
            print(f"\n[Phase 5] Script Writer (æœ¬ç·¨ä½œæˆ)...")
            script_writer_result = await self.call_agent(
                "script_writer",
                f"""ä»¥ä¸‹ã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’å…ƒã«ã€æœ¬ç·¨å°æœ¬ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## ãƒ†ãƒ¼ãƒ
{theme}

## ã‚³ãƒ³ã‚»ãƒ—ãƒˆ
{concept_output[:3000]}

## ãƒ•ãƒƒã‚¯
{hook_output[:1000]}

## æŒ‡ç¤º
1. ç«¶åˆå‹•ç”»ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å–å¾—ã—ã¦æ§‹æˆã‚’åˆ†æã—ã¦ãã ã•ã„
2. ãƒ¢ãƒ‡ãƒªãƒ³ã‚°å…ˆã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒˆãƒ¬ãƒ¼ã‚¹ã—ã¦ãã ã•ã„
3. è‡ªåˆ†ç”¨ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ãŸæœ¬ç·¨å°æœ¬ã‚’ä½œæˆã—ã¦ãã ã•ã„

MCPãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ç«¶åˆãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å–å¾—:
```
mcp__klavis-strata__execute_action(
    server_name="youtube",
    category_name="YOUTUBE_TRANSCRIPT",
    action_name="get_youtube_video_transcript",
    body_schema='{{"url": "ç«¶åˆå‹•ç”»URL"}}'
)
```
"""
            )

            script_output = self._extract_output(script_writer_result)
            script_file = SCRIPTS_DIR / f"{timestamp}_{safe_theme}_5_script.md"
            script_file.write_text(script_output, encoding="utf-8")
            output_files["script"] = str(script_file)
            print(f"  âœ… Script complete: {script_file.name}")

            # å°æœ¬çµ±åˆï¼ˆæœ¬ç·¨å«ã‚€ï¼‰
            full_script = f"# {theme}\n\n## ãƒ•ãƒƒã‚¯\n{hook_output}\n\n## ã‚³ãƒ³ã‚»ãƒ—ãƒˆ\n{concept_output}\n\n## æœ¬ç·¨å°æœ¬\n{script_output}"

            # æœ€çµ‚å°æœ¬ä¿å­˜
            final_file = FINAL_DIR / f"{timestamp}_{safe_theme}_FINAL_{current_score}pts.md"
            final_content = f"""# {theme}
## æœ€çµ‚ã‚¹ã‚³ã‚¢: {current_score}/100
## ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {iterations}å›
## ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

{full_script}
"""
            final_file.write_text(final_content, encoding="utf-8")
            output_files["final"] = str(final_file)

            print(f"\n{'='*60}")
            print(f"âœ… Pipeline Complete!")
            print(f"   Theme: {theme}")
            print(f"   Score: {current_score}/100")
            print(f"   Iterations: {iterations}")
            print(f"   Final: {final_file.name}")
            print(f"{'='*60}")

            # å°æœ¬å®Œæˆé€šçŸ¥ + Google Docsä½œæˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆMCPã§å®Ÿè¡Œï¼‰
            try:
                sys.path.insert(0, str(SNS_DIR / "_shared"))
                from mcp_email_sender import prepare_script_with_doc_and_email
                output_data = prepare_script_with_doc_and_email(
                    theme=theme,
                    score=current_score,
                    output_file=str(final_file)
                )

                # çµ±åˆJSONã‚’ä¿å­˜ï¼ˆGoogle Docs + ãƒ¡ãƒ¼ãƒ«ï¼‰
                mcp_json_file = FINAL_DIR / f"{timestamp}_{safe_theme}_mcp.json"
                with open(mcp_json_file, 'w', encoding='utf-8') as f:
                    json.dump({
                        "google_doc": output_data['google_doc']['mcp_params'],
                        "email": output_data['email']['mcp_params']
                    }, f, ensure_ascii=False, indent=2)

                print(f"ğŸ“„ Google Docs + ãƒ¡ãƒ¼ãƒ«æº–å‚™å®Œäº†: {mcp_json_file.name}")
                print(f"   â†’ MCPçµŒç”±ã§å®Ÿè¡Œã—ã¦ãã ã•ã„")
            except Exception as notify_err:
                print(f"âš ï¸ å‡ºåŠ›æº–å‚™ã‚¨ãƒ©ãƒ¼: {notify_err}")

            return PipelineResult(
                theme=theme,
                status="success" if current_score >= target_score else "below_target",
                final_score=current_score,
                iterations=iterations,
                started_at=started_at.isoformat(),
                completed_at=datetime.now().isoformat(),
                output_files=output_files
            )

        except Exception as e:
            print(f"\nâŒ Pipeline failed: {e}")

            # ã‚¨ãƒ©ãƒ¼é€šçŸ¥
            try:
                sys.path.insert(0, str(SNS_DIR / "_shared"))
                from google_notifier import notify_pipeline_error
                notify_pipeline_error("Script Generation", str(e), f"Theme: {theme}")
                print("ğŸ“§ ã‚¨ãƒ©ãƒ¼é€šçŸ¥ãƒ¡ãƒ¼ãƒ«é€ä¿¡")
            except Exception as notify_err:
                print(f"âš ï¸ é€šçŸ¥ã‚¨ãƒ©ãƒ¼: {notify_err}")

            return PipelineResult(
                theme=theme,
                status="failed",
                final_score=current_score,
                iterations=iterations,
                started_at=started_at.isoformat(),
                completed_at=datetime.now().isoformat(),
                output_files=output_files,
                error=str(e)
            )

    # ==========================================
    # ãƒãƒ£ãƒ³ãƒãƒ«ãƒ™ãƒ¼ã‚¹è‡ªå‹•å®Ÿè¡Œ
    # ==========================================

    async def run_from_channels(
        self,
        theme_prompt: Optional[str] = None,
        count: int = 1
    ) -> List[PipelineResult]:
        """
        ãƒãƒ£ãƒ³ãƒãƒ«ãƒªã‚¹ãƒˆã‹ã‚‰å„ªç§€å‹•ç”»ã‚’åˆ†æã—ã¦ãƒ†ãƒ¼ãƒã‚’ç”Ÿæˆã—ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ

        Args:
            theme_prompt: ãƒ†ãƒ¼ãƒç”Ÿæˆã®ãƒ’ãƒ³ãƒˆï¼ˆãªã‘ã‚Œã°è‡ªå‹•åˆ†æï¼‰
            count: ç”Ÿæˆã™ã‚‹å°æœ¬æ•°
        """
        # 1. å„ªç§€å‹•ç”»åˆ†æã§ãƒ†ãƒ¼ãƒå€™è£œã‚’å–å¾—
        print("\nğŸ” Analyzing outstanding videos for theme ideas...")

        research_result = await self.call_agent(
            "research",
            f"""ãƒãƒ£ãƒ³ãƒãƒ«ãƒªã‚¹ãƒˆï¼ˆresearch/data/channels.csvï¼‰ã¨
å‹•ç”»ãƒ‡ãƒ¼ã‚¿ï¼ˆresearch/data/videos.csvï¼‰ã‚’åˆ†æã—ã¦ã€
ä»Šã™ãä½œã‚‹ã¹ãå‹•ç”»ãƒ†ãƒ¼ãƒã‚’{count}ã¤ææ¡ˆã—ã¦ãã ã•ã„ã€‚

è¿½åŠ ãƒ’ãƒ³ãƒˆ: {theme_prompt or "AIãƒ»ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ç³»ã§ã€è¦–è´è€…ã®ä¸æº€ã‚’è§£æ±ºã™ã‚‹ã‚‚ã®"}

## å‡ºåŠ›å½¢å¼
ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:
```json
{{
    "themes": [
        {{
            "theme": "ãƒ†ãƒ¼ãƒã‚¿ã‚¤ãƒˆãƒ«",
            "reason": "ã“ã®ãƒ†ãƒ¼ãƒã‚’é¸ã‚“ã ç†ç”±",
            "target_audience": "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ",
            "differentiator": "å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆ"
        }}
    ]
}}
```"""
        )

        research_output = self._extract_output(research_result)

        # ãƒ†ãƒ¼ãƒæŠ½å‡º
        themes = self._extract_themes(research_output)

        if not themes:
            print("âŒ Could not generate themes. Using default.")
            themes = [{"theme": theme_prompt or "AIæ´»ç”¨ã§æ¥­å‹™åŠ¹ç‡åŒ–ã™ã‚‹æ–¹æ³•"}]

        # 2. å„ãƒ†ãƒ¼ãƒã§ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
        results = []
        for i, t in enumerate(themes[:count], 1):
            theme = t.get("theme", t) if isinstance(t, dict) else t
            print(f"\n{'='*60}")
            print(f"ğŸ“¹ Running pipeline {i}/{count}: {theme}")
            print(f"{'='*60}")

            result = await self.run_pipeline(theme)
            results.append(result)

            # çµæœã‚’ãƒ­ã‚°ã«ä¿å­˜
            await self._save_to_log(result)

        return results

    # ==========================================
    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    # ==========================================

    def _extract_output(self, result: Dict) -> str:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçµæœã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º"""
        if "error" in result:
            return f"Error: {result['error']}"

        try:
            if "artifacts" in result and result["artifacts"]:
                for artifact in result["artifacts"]:
                    for part in artifact.get("parts", []):
                        if part.get("text"):
                            return part["text"]

            if "status" in result and "message" in result["status"]:
                msg = result["status"]["message"]
                for part in msg.get("parts", []):
                    if part.get("text"):
                        return part["text"]
        except:
            pass

        return str(result)

    def _extract_score(self, review_text: str) -> int:
        """ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‹ã‚‰ã‚¹ã‚³ã‚¢æŠ½å‡º"""
        import re

        # ãƒ‘ã‚¿ãƒ¼ãƒ³: "XX/100" or "åˆè¨ˆ: XX" or "ç·åˆã‚¹ã‚³ã‚¢: XX"
        patterns = [
            r"(\d+)\s*/\s*100",
            r"åˆè¨ˆ[:\s]*\*?\*?(\d+)",
            r"ç·åˆã‚¹ã‚³ã‚¢[:\s]*(\d+)",
            r"Score[:\s]*(\d+)",
        ]

        for pattern in patterns:
            match = re.search(pattern, review_text)
            if match:
                score = int(match.group(1))
                if 0 <= score <= 100:
                    return score

        return 0

    def _extract_themes(self, text: str) -> List[Dict]:
        """ãƒ†ãƒ¼ãƒãƒªã‚¹ãƒˆã‚’æŠ½å‡º"""
        import re

        # JSONæŠ½å‡º
        json_match = re.search(r'\{[\s\S]*"themes"[\s\S]*\}', text)
        if json_match:
            try:
                data = json.loads(json_match.group())
                return data.get("themes", [])
            except:
                pass

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç®‡æ¡æ›¸ãã‹ã‚‰ãƒ†ãƒ¼ãƒæŠ½å‡º
        themes = []
        for line in text.split("\n"):
            if line.strip().startswith(("1.", "2.", "3.", "-", "â€¢")):
                theme = line.strip().lstrip("0123456789.-â€¢) ").strip()
                if theme and len(theme) > 5:
                    themes.append({"theme": theme})

        return themes[:5]

    async def _save_to_log(self, result: PipelineResult):
        """çµæœã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜"""
        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ­ã‚°ã«ä¿å­˜
        log_dir = SNS_DIR / "logs"
        log_dir.mkdir(exist_ok=True)

        log_file = log_dir / f"pipeline_{datetime.now().strftime('%Y%m%d')}.json"

        logs = []
        if log_file.exists():
            try:
                logs = json.loads(log_file.read_text())
            except:
                pass

        logs.append(asdict(result))
        log_file.write_text(json.dumps(logs, ensure_ascii=False, indent=2))

        print(f"ğŸ“ Logged to: {log_file}")

    # ==========================================
    # ãƒã‚ºå‹•ç”»ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆPhase1 â†’ Phase2é€£æºï¼‰
    # ==========================================

    async def run_from_buzz(
        self,
        threshold: float = 5.0,
        days: int = 90,
        count: int = 1
    ) -> List[PipelineResult]:
        """
        ãƒã‚ºå‹•ç”»ã‚’æ¤œå‡º â†’ ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå–å¾— â†’ å°æœ¬ç”Ÿæˆ

        ãƒ•ãƒ­ãƒ¼:
        1. ChannelManager.auto_discover_buzz() ã§ãƒã‚ºå‹•ç”»æ¤œå‡º
        2. MCPã§ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå–å¾—
        3. Script Writer Agent ã«é€ä¿¡
        4. å°æœ¬ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ

        Args:
            threshold: PRã—ãã„å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5.0ï¼‰
            days: ç›´è¿‘Næ—¥ä»¥å†…ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ90æ—¥ï¼‰
            count: ç”Ÿæˆã™ã‚‹å°æœ¬æ•°
        """
        print("\n" + "=" * 60)
        print("ğŸ”¥ Buzz Video â†’ Script Generation Pipeline")
        print("=" * 60)

        # Phase 1: ãƒã‚ºå‹•ç”»æ¤œå‡º
        print("\n[Phase 1] Detecting buzz videos...")

        try:
            sys.path.insert(0, str(SCRIPT_DIR / "research"))
            from channel_manager import ChannelManager

            manager = ChannelManager()

            # ãƒ‡ãƒ¼ã‚¿ãŒãªã‘ã‚Œã°è‡ªå‹•fetch
            videos = manager.load_videos()
            if not videos:
                print("  ğŸ“¡ No video data found. Fetching from YouTube API...")
                channels = manager.load_channels()
                if not channels:
                    print("  âŒ No channels registered. Add channels first:")
                    print("     python research/channel_manager.py add --channel \"ãƒãƒ£ãƒ³ãƒãƒ«å\"")
                    return []

                # ãƒãƒ£ãƒ³ãƒãƒ«IDãŒãªã‘ã‚Œã°è§£æ±º
                needs_resolve = [c for c in channels if not c.channel_id]
                if needs_resolve:
                    print(f"  ğŸ” Resolving {len(needs_resolve)} channel IDs...")
                    manager.resolve_channel_ids()

                # å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚’fetch
                print(f"  ğŸ“¥ Fetching videos from {len(channels)} channels...")
                manager.fetch_all_channels(top_n=20, force=True)
                videos = manager.load_videos()
                print(f"  âœ… Fetched {len(videos)} videos")

            discover_result = manager.auto_discover_buzz(
                threshold=threshold,
                min_views=10000,
                days=days
            )
        except Exception as e:
            print(f"âŒ ChannelManager error: {e}")
            import traceback
            traceback.print_exc()
            return []

        buzz_videos = discover_result.get("buzz_videos", [])

        if not buzz_videos:
            print("âŒ No buzz videos found with current threshold")
            print(f"  â†’ Threshold: PR >= {threshold}x, Last {days} days")
            print("  â†’ Try lowering threshold: --threshold 2.0")

            # ã—ãã„å€¤ã‚’ä¸‹ã’ã¦å†æ¤œç´¢ã‚’ææ¡ˆ
            lower_result = manager.find_outstanding_videos(threshold=2.0, min_views=1000)
            if lower_result:
                print(f"  ğŸ’¡ Found {len(lower_result)} videos with PR >= 2.0")
                print(f"     Top: {lower_result[0].title[:40]}... (PR: {lower_result[0].performance_ratio:.1f}x)")
            return []

        print(f"âœ… Found {len(buzz_videos)} buzz videos")
        for i, v in enumerate(buzz_videos[:5], 1):
            print(f"  {i}. {v['title'][:40]}... (PR: {v['performance_ratio']}x)")

        # ãƒã‚ºå‹•ç”»æ¤œå‡ºé€šçŸ¥ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆMCPã§é€ä¿¡ï¼‰
        try:
            sys.path.insert(0, str(SNS_DIR / "_shared"))
            from mcp_email_sender import prepare_buzz_detection_email
            buzz_email = prepare_buzz_detection_email(buzz_videos, threshold)

            # ãƒ¡ãƒ¼ãƒ«é€ä¿¡ç”¨JSONã‚’ä¿å­˜ï¼ˆClaude CodeãŒå®Ÿè¡Œï¼‰
            email_json_file = OUTPUT_DIR / f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_buzz_email.json"
            import json
            with open(email_json_file, 'w', encoding='utf-8') as f:
                json.dump(buzz_email['mcp_params'], f, ensure_ascii=False, indent=2)

            print(f"ğŸ“§ ãƒã‚ºå‹•ç”»æ¤œå‡ºãƒ¡ãƒ¼ãƒ«æº–å‚™å®Œäº†: {email_json_file.name}")
            print(f"   â†’ MCPçµŒç”±ã§é€ä¿¡ã—ã¦ãã ã•ã„")
        except Exception as e:
            print(f"âš ï¸ Email prep error: {e}")

        # Phase 2: ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå–å¾—æŒ‡ç¤ºã‚’ç”Ÿæˆ
        print("\n[Phase 2] Generating transcript fetch instructions...")

        try:
            sys.path.insert(0, str(SNS_DIR / "_shared"))
            from buzz_to_script_pipeline import BuzzToScriptPipeline

            pipeline = BuzzToScriptPipeline()
            pipeline_info = pipeline.process_buzz_videos(buzz_videos)

            # æŒ‡ç¤ºã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            instructions_file = OUTPUT_DIR / f"{timestamp}_transcript_instructions.md"
            instructions_file.write_text(pipeline_info["transcript_instructions"], encoding="utf-8")
            print(f"âœ… Instructions saved: {instructions_file.name}")

        except Exception as e:
            print(f"âš ï¸ Pipeline info error: {e}")
            pipeline_info = None

        # Phase 3: å„ãƒã‚ºå‹•ç”»ã‹ã‚‰å°æœ¬ç”Ÿæˆ
        print("\n[Phase 3] Running script generation pipeline...")

        results = []
        for i, video in enumerate(buzz_videos[:count], 1):
            # ãƒã‚ºå‹•ç”»æƒ…å ±ã‹ã‚‰ãƒ†ãƒ¼ãƒã‚’ç”Ÿæˆ
            video_title = video.get("title", "")
            channel_name = video.get("channel_name", "")
            pr = video.get("performance_ratio", 0)

            theme = f"ã€Œ{video_title}ã€ã®ã‚ˆã†ãªå‹•ç”»ã‚’ä½œã‚‹"

            print(f"\n--- Pipeline {i}/{count}: {theme[:40]}... ---")

            # Script Writer ã«ç›´æ¥é€ä¿¡ï¼ˆãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆå–å¾—æŒ‡ç¤ºä»˜ãï¼‰
            script_prompt = f"""ä»¥ä¸‹ã®ãƒã‚ºå‹•ç”»ã‚’å‚è€ƒã«ã€åŒæ§˜ã®ãƒ†ãƒ¼ãƒã§å°æœ¬ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## ãƒã‚ºå‹•ç”»æƒ…å ±
- ã‚¿ã‚¤ãƒˆãƒ«: {video_title}
- ãƒãƒ£ãƒ³ãƒãƒ«: {channel_name}
- PR (Performance Ratio): {pr:.1f}x
- URL: https://youtube.com/watch?v={video.get('video_id', '')}

## ã‚¿ã‚¹ã‚¯
1. ã¾ãšä¸Šè¨˜å‹•ç”»ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’MCPã§å–å¾—ã—ã¦ãã ã•ã„:
```
mcp__klavis-strata__execute_action(
    server_name="youtube",
    category_name="YOUTUBE_TRANSCRIPT",
    action_name="get_youtube_video_transcript",
    body_schema='{{"url": "https://youtube.com/watch?v={video.get('video_id', '')}"}}'
)
```

2. ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’åˆ†æã—ã€æ§‹æˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º

3. æˆåŠŸè¦å› ã‚’ç‰¹å®š

4. åŒæ§˜ã®ãƒ†ãƒ¼ãƒãƒ»æ§‹æˆã§ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã®å°æœ¬ã‚’ä½œæˆ
   - PASTOR + AREAæ§‹æˆã‚’ä½¿ç”¨
   - è‡ªåˆ†ã®è¦–ç‚¹ãƒ»çµŒé¨“ã‚’å…¥ã‚Œã‚‹
   - å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆã‚’æ˜ç¢ºã«
"""

            script_result = await self.call_agent("script_writer", script_prompt)
            script_output = self._extract_output(script_result)

            # ä¿å­˜
            safe_title = video_title.replace("/", "_").replace(" ", "_")[:30]
            script_file = SCRIPTS_DIR / f"{timestamp}_{safe_title}_buzz_script.md"
            script_file.write_text(f"# ãƒã‚ºå‹•ç”»å‚è€ƒå°æœ¬\n\n## å…ƒå‹•ç”»\n- {video_title}\n- PR: {pr}x\n\n## ç”Ÿæˆå°æœ¬\n{script_output}", encoding="utf-8")

            print(f"âœ… Script saved: {script_file.name}")

            # å°æœ¬å®Œæˆé€šçŸ¥ + Google Docsä½œæˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆMCPã§å®Ÿè¡Œï¼‰
            try:
                from mcp_email_sender import prepare_script_with_doc_and_email
                output_data = prepare_script_with_doc_and_email(
                    theme=theme,
                    score=0,  # ãƒ¬ãƒ“ãƒ¥ãƒ¼æœªå®Ÿæ–½
                    output_file=str(script_file),
                    buzz_video=video
                )

                # çµ±åˆJSONã‚’ä¿å­˜ï¼ˆGoogle Docs + ãƒ¡ãƒ¼ãƒ«ï¼‰
                mcp_json_file = OUTPUT_DIR / f"{timestamp}_{safe_title}_mcp.json"
                with open(mcp_json_file, 'w', encoding='utf-8') as f:
                    json.dump({
                        "google_doc": output_data['google_doc']['mcp_params'],
                        "email": output_data['email']['mcp_params']
                    }, f, ensure_ascii=False, indent=2)

                print(f"ğŸ“„ Google Docs + ãƒ¡ãƒ¼ãƒ«æº–å‚™å®Œäº†: {mcp_json_file.name}")
            except Exception as notify_err:
                print(f"âš ï¸ å‡ºåŠ›æº–å‚™ã‚¨ãƒ©ãƒ¼: {notify_err}")

            # çµæœã‚’è¿½åŠ 
            results.append(PipelineResult(
                theme=theme,
                status="success",
                final_score=0,  # ãƒ¬ãƒ“ãƒ¥ãƒ¼æœªå®Ÿæ–½
                iterations=1,
                started_at=datetime.now().isoformat(),
                completed_at=datetime.now().isoformat(),
                output_files={"script": str(script_file)}
            ))

        print("\n" + "=" * 60)
        print(f"âœ… Buzz Pipeline Complete: {len(results)} scripts generated")
        print("=" * 60)

        return results


# ==========================================
# CLI
# ==========================================

async def main():
    import argparse

    parser = argparse.ArgumentParser(description="YouTube Pipeline Runner")
    parser.add_argument("command", choices=["run", "auto", "check", "buzz"],
                       help="run: æŒ‡å®šãƒ†ãƒ¼ãƒã§å®Ÿè¡Œ, auto: è‡ªå‹•ãƒ†ãƒ¼ãƒç”Ÿæˆ, buzz: ãƒã‚ºå‹•ç”»â†’å°æœ¬, check: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç¢ºèª")
    parser.add_argument("--theme", "-t", help="å‹•ç”»ãƒ†ãƒ¼ãƒï¼ˆrunã‚³ãƒãƒ³ãƒ‰ç”¨ï¼‰")
    parser.add_argument("--count", "-n", type=int, default=1, help="ç”Ÿæˆå°æœ¬æ•°")
    parser.add_argument("--hint", "-H", help="ãƒ†ãƒ¼ãƒç”Ÿæˆãƒ’ãƒ³ãƒˆï¼ˆautoã‚³ãƒãƒ³ãƒ‰ç”¨ï¼‰")
    parser.add_argument("--threshold", "-T", type=float, default=5.0, help="PRã—ãã„å€¤ï¼ˆbuzzã‚³ãƒãƒ³ãƒ‰ç”¨ï¼‰")
    parser.add_argument("--days", "-d", type=int, default=90, help="ç›´è¿‘Næ—¥ä»¥å†…ï¼ˆbuzzã‚³ãƒãƒ³ãƒ‰ç”¨ï¼‰")
    args = parser.parse_args()

    runner = PipelineRunner()

    try:
        if args.command == "check":
            print("ğŸ” Checking agent status...")
            status = await runner.check_agents()
            print("\nPhase 1 - Data Collection:")
            for name in ["channel_monitor", "video_collector", "trend_analyzer"]:
                if name in status:
                    icon = "âœ…" if status[name] else "âŒ"
                    print(f"  {icon} {name}: {'Running' if status[name] else 'Not Running'}")
            print("\nPhase 2 - Script Generation:")
            for name in ["coordinator", "research", "hook", "concept", "reviewer", "improver", "script_writer"]:
                if name in status:
                    icon = "âœ…" if status[name] else "âŒ"
                    print(f"  {icon} {name}: {'Running' if status[name] else 'Not Running'}")

        elif args.command == "run":
            if not args.theme:
                print("âŒ Please specify theme with --theme")
                return

            result = await runner.run_pipeline(args.theme)
            print(f"\nResult: {result.status}")
            print(f"Final Score: {result.final_score}")
            print(f"Output: {result.output_files.get('final', 'N/A')}")

        elif args.command == "auto":
            results = await runner.run_from_channels(
                theme_prompt=args.hint,
                count=args.count
            )

            print(f"\n{'='*60}")
            print(f"ğŸ“Š Summary: {len(results)} pipelines completed")
            for r in results:
                status_icon = "âœ…" if r.status == "success" else "âš ï¸"
                print(f"  {status_icon} {r.theme[:30]}... â†’ {r.final_score}/100")

        elif args.command == "buzz":
            print("ğŸ”¥ Running Buzz Video â†’ Script Generation Pipeline")
            print(f"   Threshold: PR >= {args.threshold}x")
            print(f"   Period: Last {args.days} days")
            print(f"   Scripts: {args.count}")

            results = await runner.run_from_buzz(
                threshold=args.threshold,
                days=args.days,
                count=args.count
            )

            print(f"\n{'='*60}")
            print(f"ğŸ“Š Summary: {len(results)} scripts generated from buzz videos")
            for r in results:
                print(f"  âœ… {r.theme[:40]}...")
                if r.output_files.get("script"):
                    print(f"     â†’ {Path(r.output_files['script']).name}")

    finally:
        await runner.close()


if __name__ == "__main__":
    asyncio.run(main())
